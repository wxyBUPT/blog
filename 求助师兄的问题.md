#问题

400000000（4亿）个key 外排，最主要的目的是提高io。

想到如下方法：

* 在内存中批量有序插入(avl，或者二叉树) -> 每2500000写入磁盘，分 160批写入，最后做 160 路归并排序（或者路数更小，归并次数更多）
* 内存中批量插入  -> 每 2500000 条做快速排序，写入磁盘，之后同样做归并排序

想问师兄师姐的第一个问题是上面方法是否可行，批量快排和二叉树或者avl 哪个更好点
I
第二个问题是有人说归并排序太慢，所以有没有更好的方法？

```  
 */
public class ComparableKeysByBuyerCreateTimeOrderId implements Indexable,Comparable<ComparableKeysByBuyerCreateTimeOrderId>,Serializable{

    private String buyerId;
    private Long createTime;
    private Long orderId;
    private DiskLoc diskLoc;

    @Override
    public int compareTo(ComparableKeysByBuyerCreateTimeOrderId o) {
        if(this.orderId==null||this.createTime==null||this.buyerId==null
                ||o.orderId==null||o.createTime==null||o.buyerId==null){
            throw new RuntimeException("Bad keys, there is a bug maybe");
        }
        int ret = this.buyerId.compareTo(o.buyerId);
        if(ret!=0){
            return ret;
        }
        ret = this.createTime.compareTo(o.createTime);
        if(ret != 0){
            return ret;
        }
        ret = this.orderId.compareTo(o.orderId);
        return ret;
    }

    public ComparableKeysByBuyerCreateTimeOrderId(
            String buyerId,Long createTime,Long orderId,DiskLoc diskLoc
    ){
        this.buyerId = buyerId;
        this.createTime = createTime;
        this.orderId = orderId;
        this.diskLoc = diskLoc;
    }

    @Override
    public DiskLoc getDataDiskLoc() {
        return diskLoc;
    }

    @Override
    public String toString(){
        StringBuilder sb = new StringBuilder();
        sb.append(ComparableKeysByBuyerCreateTimeOrderId.class.getName()+" : ");
        sb.append("BuyerId: " + buyerId).append(", createTime: " + createTime + ",orderId: " + orderId);
        return sb.toString();
    }

}
``` is